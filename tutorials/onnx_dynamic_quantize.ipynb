{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert onnx model\n",
    "1. query_retrieve\n",
    "2. context_retrieve\n",
    "3. rerank\n",
    "\n",
    "Requirements:\n",
    "1. optinum\n",
    "2. onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!optimum-cli export onnx \\\n",
    "    --library transformers \\\n",
    "    --task text-classification \\\n",
    "    -m ./mbert-rerank-base \\\n",
    "    --optimize O1 ./onnx_convert_outputs/mbert-rerank-onnx \\\n",
    "    --opset 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!optimum-cli export onnx \\\n",
    "    --library transformers \\\n",
    "    --task feature-extraction \\\n",
    "    -m ./mbert-retrieve-qry-base \\\n",
    "    --optimize O1 ./onnx_convert_outputs/mbert-retrieve-qry-onnx \\\n",
    "    --opset 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!optimum-cli export onnx \\\n",
    "    --library transformers \\\n",
    "    --task feature-extraction \\\n",
    "    -m ./mbert-retrieve-ctx-base \\\n",
    "    --optimize O1 ./onnx_convert_outputs/mbert-retrieve-ctx-onnx \\\n",
    "    --opset 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "* `--optimize` ranges from [01, 02, 03, 04]. Increasing value will lead to accuracy dropping.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize Dynamic Onnx Model\n",
    "Requirements:\n",
    "* onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# convert\n",
    "model_fp32 = './onnx_convert_outputs/mbert-retrieve-qry-onnx/model.onnx'\n",
    "model_quant = './onnx_convert_outputs/mbert-retrieve-qry-onnx/model.quant.onnx'\n",
    "if os.path.exists(model_quant):\n",
    "    os.remove(model_quant)\n",
    "    os.remove(model_quant + '.data')\n",
    "quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8, use_external_data_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# convert\n",
    "model_fp32 = './onnx_convert_outputs/mbert-retrieve-ctx-onnx/model.onnx'\n",
    "model_quant = './onnx_convert_outputs/mbert-retrieve-ctx-onnx/model.quant.onnx'\n",
    "if os.path.exists(model_quant):\n",
    "    os.remove(model_quant)\n",
    "    os.remove(model_quant + '.data')\n",
    "quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8, use_external_data_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "NOTE: missing rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "def compute_loss(scores, target):\n",
    "    return cross_entropy(scores, target)\n",
    "\n",
    "def compute_similarity(q_reps, p_reps):\n",
    "    if not isinstance(q_reps, torch.Tensor):\n",
    "        q_reps = torch.tensor(q_reps)\n",
    "    if not isinstance(p_reps, torch.Tensor):\n",
    "        p_reps = torch.tensor(p_reps)\n",
    "    return torch.matmul(q_reps, p_reps.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# CLS Pooling - Take output from first token\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:,0].detach().cpu()\n",
    "\n",
    "def onnx_predict(onnx_model, encoded_input: dict):\n",
    "    encoded_input = {key: tensor.numpy() for key, tensor in encoded_input.items()}\n",
    "    # Move input to device\n",
    "    start_time = time.time()\n",
    "    model_output = onnx_model.run(None, encoded_input)\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    # Perform pooling\n",
    "    embeddings = model_output[0][:, 0] # cls embeddings\n",
    "    return embeddings, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import time\n",
    "from typing import Callable\n",
    "import inspect\n",
    "\n",
    "def eval_accuracy(\n",
    "    data, \n",
    "    encode_fn = Callable, \n",
    "    num_passages=65, \n",
    "    model_ctx=None, \n",
    "    model_qry=None, \n",
    "    tokenizer_ctx=None, \n",
    "    tokenizer_query=None,\n",
    "    device='cpu'\n",
    "):\n",
    "\n",
    "    assert model_ctx is not None, \"model_ctx is required\"\n",
    "    assert model_qry is not None, \"model_qry is required\"\n",
    "    assert tokenizer_ctx is not None, \"tokenizer_ctx is required\"\n",
    "    assert tokenizer_query is not None, \"tokenizer_query is required\"\n",
    "    assert 'query' in data.column_names, \"data must have query column\"\n",
    "    assert 'positive' in data.column_names, \"data must have positive column\"\n",
    "    assert 'negatives' in data.column_names, \"data must have negatives column\"\n",
    "    # len of arguemtn of encode_fn must be 4\n",
    "    # print(inspect.getargspec(encode_fn).args)\n",
    "    assert len(inspect.getargspec(encode_fn).args) == 4, \"encode_fn must have 4 arguments\"\n",
    "\n",
    "    accuracy = 0\n",
    "\n",
    "    if device != \"cpu\":\n",
    "        model_ctx = model_ctx.to(device)\n",
    "        model_qry = model_qry.to(device)\n",
    "\n",
    "    time_query_total = 0\n",
    "    time_query_run = 0\n",
    "    time_passage_total = 0\n",
    "    time_passage_run = 0\n",
    "\n",
    "    for i in tqdm(range(len(data))):\n",
    "\n",
    "        start_time = time.time()\n",
    "        query, time_query = encode_fn([data[i]['query']], model_qry, tokenizer_query, device)\n",
    "        end_time = time.time() - start_time\n",
    "        time_query_total += end_time\n",
    "        time_query_run += time_query\n",
    "\n",
    "        # concate 10 passages\n",
    "        concate_passage = [data[i]['positive']] + data[i]['negatives'][:num_passages-1]\n",
    "        start_time = time.time()\n",
    "        encoded_passages, time_ctx = encode_fn(concate_passage, model_ctx, tokenizer_ctx, device)\n",
    "        end_time = time.time() - start_time\n",
    "        time_passage_total += end_time\n",
    "        time_passage_run += time_ctx\n",
    "\n",
    "        # accuracy\n",
    "        scores = compute_similarity(query, encoded_passages)\n",
    "        if scores.argmax(dim=1).detach().numpy() != 0:\n",
    "            continue\n",
    "        accuracy += 1\n",
    "\n",
    "    return accuracy / len(data), time_query_run/ len(data), time_passage_run/ len(data), time_query_total/ len(data), time_passage_total/ len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Encode text\n",
    "def encode_onnx(texts, model, tokenizer, device='cpu'):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    #\n",
    "    embeddings, end_time = onnx_predict(model, encoded_input)\n",
    "    #\n",
    "    return embeddings, end_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import concatenate_datasets\n",
    "en_eval = datasets.load_dataset('tiennv/mmarco-passage-vi', split='train[-500:]')\n",
    "vi_eval = datasets.load_dataset('tiennv/mmarco-passage-vi', split='train[-500:]')\n",
    "\n",
    "dataset_eval = concatenate_datasets([en_eval, vi_eval])\n",
    "dataset_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_query = AutoTokenizer.from_pretrained(\"mbert-retrieve-qry-base\")\n",
    "tokenizer_ctx = AutoTokenizer.from_pretrained(\"mbert-retrieve-ctx-base\")\n",
    "\n",
    "# raw\n",
    "# query_path = \"onnx_convert_outputs/mbert-retrieve-qry-onnx/model.onnx\"\n",
    "# ctx_path = \"onnx_convert_outputs/mbert-retrieve-ctx-onnx/model.onnx\"\n",
    "\n",
    "# quant dynamic\n",
    "# query_path = \"onnx_convert_outputs/mbert-retrieve-qry-onnx/model.quant.onnx\"\n",
    "# ctx_path = \"onnx_convert_outputs/mbert-retrieve-ctx-onnx/model.quant.onnx\"\n",
    "\n",
    "# quantize calib\n",
    "query_path = \"onnx_convert_outputs/mbert-retrieve-qry-onnx/qry_quant_percential_calib.onnx\"\n",
    "ctx_path = \"onnx_convert_outputs/mbert-retrieve-ctx-onnx/ctx_quant_percential_calib.onnx\"\n",
    "\n",
    "\n",
    "providers = [(\"CUDAExecutionProvider\", {\"device_id\": 0,\n",
    "                                        \"user_compute_stream\": str(torch.cuda.current_stream().cuda_stream),\n",
    "                                        \"cudnn_conv_algo_search\": \"DEFAULT\",\n",
    "                                        })]\n",
    "\n",
    "# providers = [\"CPUExecutionProvider\"]\n",
    "\n",
    "sess_options = onnxruntime.SessionOptions()\n",
    "# sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel\n",
    "query_session = onnxruntime.InferenceSession(query_path, sess_options, providers=providers)\n",
    "ctx_session = onnxruntime.InferenceSession(ctx_path, sess_options, providers=providers)\n",
    "query_session, ctx_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# test dummy\n",
    "encode_onnx([dataset_eval[0]['query']], query_session, tokenizer_query)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "accuracy, time_query_run, time_passage_run, time_query_total, time_passage_total = eval_accuracy(\n",
    "    dataset_eval, \n",
    "    encode_onnx,\n",
    "    num_passages=10, \n",
    "    model_ctx=ctx_session,\n",
    "    model_qry=query_session, \n",
    "    tokenizer_ctx=tokenizer_ctx, \n",
    "    tokenizer_query=tokenizer_query, \n",
    "    device='cpu'\n",
    ")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Time Query Run: {time_query_run}\")\n",
    "print(f\"Time Passage Run: {time_passage_run}\")\n",
    "print(f\"Time Query Total: {time_query_total}\")\n",
    "print(f\"Time Passage Total: {time_passage_total}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
