# rtvserving
## Description
This project provides a comprehensive guide for TensorRT model optimization and deployment. Key features include:

- ONNX dynamic quantization
- PyTorch-based calibration with Pytorch Quantization
- TensorRT-LLM BertAttentionPlugin integration
- Custom TensorRT calibration pipeline for low-resource models
- Deployment with Rayserve

The toolkit aims to streamline the process of converting deep learning models to optimized TensorRT engines while maintaining accuracy and performance.

## Onnx Dynamic Quantization
 

## TensorRT-LLM BertAttentionPlugin


## TensorRT Calibration API


## TensorRT Custom Network Lowcode


## Reference
